{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install datasets transformers rouge-score nltk contractions torchmetrics scipy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-03T14:54:19.385362Z","iopub.execute_input":"2023-05-03T14:54:19.386078Z","iopub.status.idle":"2023-05-03T14:54:32.873404Z","shell.execute_reply.started":"2023-05-03T14:54:19.386037Z","shell.execute_reply":"2023-05-03T14:54:32.872172Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.27.4)\nCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (3.2.4)\nCollecting contractions\n  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\nRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.7/site-packages (0.11.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (1.7.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (23.0)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2023.1.0)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.13.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.64.1)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.6)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.2.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.11.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from rouge-score) (1.16.0)\nCollecting textsearch>=0.0.21\n  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\nRequirement already satisfied: torch>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (1.13.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (4.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.1.1)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (22.2.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.8.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.4)\nCollecting pyahocorasick\n  Downloading pyahocorasick-2.0.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (101 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting anyascii\n  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.11.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2023.3)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=dfe831df27bf828de427126a97a1eefaef29a91fec2f453718495134e75d7667\n  Stored in directory: /root/.cache/pip/wheels/8e/6b/70/59daa7c90a238610e34bac5916e001fe3d9bb0ec59c8cf5518\nSuccessfully built rouge-score\nInstalling collected packages: pyahocorasick, anyascii, textsearch, rouge-score, contractions\nSuccessfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 rouge-score-0.1.2 textsearch-0.0.24\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import gc\nimport time\nimport re\nimport argparse\nimport warnings\nimport os\n\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchmetrics\n\nimport nltk\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('omw-1.4')\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nimport spacy\nimport contractions\n\nfrom tqdm.auto import tqdm\n\nimport transformers\nimport logging\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# device = 'cpu'","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:54:32.876449Z","iopub.execute_input":"2023-05-03T14:54:32.876929Z","iopub.status.idle":"2023-05-03T14:54:58.386335Z","shell.execute_reply.started":"2023-05-03T14:54:32.876873Z","shell.execute_reply":"2023-05-03T14:54:58.385194Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"}]},{"cell_type":"code","source":"# Basic Preprocessing\ndef expand_contractions(sentence):\n  contractions_expanded = [contractions.fix(word) for word in sentence.split()]\n  return ' '.join(contractions_expanded)\n\ndef lower_case(sentence):\n  return ' '.join([word.lower() for word in sentence.split()])\n\ndef remove_punctuation(sentence):\n  return ' '.join([re.sub(r'[^\\w\\s]', '', word) for word in sentence.split()])\n\ndef preprocess(lst, process=True,):\n  if process == True:\n    for i, sent in enumerate(lst):\n      lst[i] = lower_case(remove_punctuation(expand_contractions(sent)))\n      \n  \n  return lst","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:54:58.388276Z","iopub.execute_input":"2023-05-03T14:54:58.388686Z","iopub.status.idle":"2023-05-03T14:54:58.402642Z","shell.execute_reply.started":"2023-05-03T14:54:58.388643Z","shell.execute_reply":"2023-05-03T14:54:58.401746Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Importing only the data for which we have summaries\ndata_with_summaries = pd.read_csv('/kaggle/input/tweetsummemnlp2017/9_tweet_grouped_data_no_dups.csv').iloc[:3612]","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:54:58.405861Z","iopub.execute_input":"2023-05-03T14:54:58.406240Z","iopub.status.idle":"2023-05-03T14:54:58.523146Z","shell.execute_reply.started":"2023-05-03T14:54:58.406202Z","shell.execute_reply":"2023-05-03T14:54:58.522187Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Importing the summaries\nsummaries = pd.read_csv('/kaggle/input/tweetsummemnlp2017/ChatGPT-Summaries.csv', sep=';')","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:54:58.524627Z","iopub.execute_input":"2023-05-03T14:54:58.524973Z","iopub.status.idle":"2023-05-03T14:54:58.541466Z","shell.execute_reply.started":"2023-05-03T14:54:58.524935Z","shell.execute_reply":"2023-05-03T14:54:58.540521Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Preprocesiing the summaries\nstart_time = time.time()\nsummaries['generated_summary'] = preprocess(list(summaries['generated_summary']))\nprint('Time taken for preprocessing', time.time() - start_time)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:54:58.542771Z","iopub.execute_input":"2023-05-03T14:54:58.543116Z","iopub.status.idle":"2023-05-03T14:54:58.649732Z","shell.execute_reply.started":"2023-05-03T14:54:58.543077Z","shell.execute_reply":"2023-05-03T14:54:58.648613Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Time taken for preprocessing 0.10208368301391602\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Creating the Dataset","metadata":{}},{"cell_type":"code","source":"class SummaryTrainDataset(Dataset):\n    def __init__(self, tokenizer, tweet_data, summary_data, max_len=256):\n\n        self.tweet_column = \"tweet\"\n        self.group_id_column = \"group_id\"\n        self.summary_column = \"generated_summary\"\n        self.tweet_data = tweet_data\n        self.summary_data = summary_data\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n        \n        self.inputs = []\n        self.targets = []\n        self.input_texts = []\n        self.summary_texts = []\n\n        self._build()\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, index):\n        ip = self.inputs[index]\n        tgt = self.targets[index]\n        ip_text = self.input_texts[index]\n        tgt_text = self.summary_texts[index]\n        \n        \n        return {\"input\": ip, \"target\": tgt, \"input_text\": ip_text, \"target_text\": tgt_text}\n\n\n    def _build(self):\n        for idx in tqdm(range(len(self.summary_data))):\n            summ = self.summary_data.iloc[idx][self.summary_column]\n            tweet_subset = self.tweet_data[self.tweet_data[self.group_id_column] == self.summary_data.iloc[idx][self.group_id_column]]['tweet'].iloc[:8]\n            ip = '. '.join(list(tweet_subset))\n            \n            del tweet_subset\n            gc.collect()\n            \n            self.input_texts.append(ip)\n            self.summary_texts.append(summ)\n            \n            ip = \"summarize: \" + ip\n            \n            tokenized_inputs = self.tokenizer(\n                ip, max_length=self.max_len, padding='max_length', truncation=True, return_tensors='pt'\n            )\n            \n            tokenized_targets = self.tokenizer(\n                text_target=summ, max_length=self.max_len, padding='max_length', truncation=True, return_tensors='pt'\n            )\n            \n            self.inputs.append(tokenized_inputs)\n            self.targets.append(tokenized_targets)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:54:58.651125Z","iopub.execute_input":"2023-05-03T14:54:58.651518Z","iopub.status.idle":"2023-05-03T14:54:58.663813Z","shell.execute_reply.started":"2023-05-03T14:54:58.651465Z","shell.execute_reply":"2023-05-03T14:54:58.662733Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class SummaryTestDataset(Dataset):\n    def __init__(self, tokenizer, tweet_data, summary_data, max_len=256):\n\n        self.tweet_column = \"tweet\"\n        self.group_id_column = \"group_id\"\n        self.summary_column = \"generated_summary\"\n        self.tweet_data = tweet_data\n        self.summary_data = summary_data\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n        \n        self.inputs = []\n        self.targets = []\n        self.input_texts = []\n        self.summary_texts = []\n\n        self._build()\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, index):\n        ip = self.inputs[index]\n        tgt = self.targets[index]\n        ip_text = self.input_texts[index]\n        tgt_text = self.summary_texts[index]\n        \n        return {\"input\": ip, \"target\": tgt, \"input_text\": ip_text, \"target_text\": tgt_text}\n\n\n    def _build(self):\n        for idx in tqdm(range(len(self.summary_data))):\n            summ = self.summary_data.iloc[idx][self.summary_column]\n            tweet_subset = self.tweet_data[self.tweet_data[self.group_id_column] == self.summary_data.iloc[idx][self.group_id_column]]['tweet'].iloc[8:]\n            ip = '. '.join(list(tweet_subset))\n            \n            del tweet_subset\n            gc.collect()\n            \n            self.input_texts.append(ip)\n            self.summary_texts.append(summ)\n            \n            ip = \"summarize: \" + ip\n            summ = summ\n            \n            tokenized_inputs = self.tokenizer(\n                ip, max_length=self.max_len, padding='max_length', truncation=True, return_tensors='pt'\n            )\n            \n            tokenized_targets = self.tokenizer(\n                text_target=summ, max_length=self.max_len, padding='max_length', truncation=True, return_tensors='pt'\n            )\n            \n            self.inputs.append(tokenized_inputs)\n            self.targets.append(tokenized_targets)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:54:58.665620Z","iopub.execute_input":"2023-05-03T14:54:58.666103Z","iopub.status.idle":"2023-05-03T14:54:58.679258Z","shell.execute_reply.started":"2023-05-03T14:54:58.666067Z","shell.execute_reply":"2023-05-03T14:54:58.678290Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = \"t5-base\"","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:54:58.682519Z","iopub.execute_input":"2023-05-03T14:54:58.682774Z","iopub.status.idle":"2023-05-03T14:54:58.692292Z","shell.execute_reply.started":"2023-05-03T14:54:58.682749Z","shell.execute_reply":"2023-05-03T14:54:58.691341Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from transformers import T5TokenizerFast\n\ntokenizer = T5TokenizerFast.from_pretrained(\n    model_checkpoint,\n    model_max_length = 256,\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:54:58.696976Z","iopub.execute_input":"2023-05-03T14:54:58.697285Z","iopub.status.idle":"2023-05-03T14:55:00.383014Z","shell.execute_reply.started":"2023-05-03T14:54:58.697257Z","shell.execute_reply":"2023-05-03T14:55:00.381938Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f15c94a1e2b24420b3b5c0333a2de187"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2af6d4d141ae4937b339a5417e71366d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"591cc837992f4d23b0f4a0368e1fca58"}},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = SummaryTrainDataset(tokenizer, data_with_summaries, summaries)\ntest_dataset = SummaryTestDataset(tokenizer, data_with_summaries, summaries)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:55:00.384767Z","iopub.execute_input":"2023-05-03T14:55:00.385163Z","iopub.status.idle":"2023-05-03T14:57:37.333603Z","shell.execute_reply.started":"2023-05-03T14:55:00.385119Z","shell.execute_reply":"2023-05-03T14:57:37.332562Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/301 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37ff870e27d844768b99db041882ac47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/301 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9679390a322e45fa854c111f86d60636"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Models","metadata":{}},{"cell_type":"code","source":"# Discriminator Model: Bert as a Sequence Classifier\nfrom transformers import BertForSequenceClassification, BertTokenizerFast\n\ndiscriminator_checkpoint = 'bert-base-uncased'\ndiscriminator_tokenizer = BertTokenizerFast.from_pretrained(\n    discriminator_checkpoint,\n)\ndiscriminator = BertForSequenceClassification.from_pretrained(discriminator_checkpoint,\n                                                              num_labels = 1,\n                                                             ).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:57:37.347678Z","iopub.execute_input":"2023-05-03T14:57:37.348050Z","iopub.status.idle":"2023-05-03T14:57:42.169725Z","shell.execute_reply.started":"2023-05-03T14:57:37.348012Z","shell.execute_reply":"2023-05-03T14:57:42.168662Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43c46191b33a4a22b8fcc983483bf704"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"714cf6bdb0d24d0cab72b5f9c00db119"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be9ba62511314202b4a813214740271c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe2b9342c92f4b1c87b003ffb1ca29fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fd05594eb4a4e46b807cf61cbf284d7"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Generator Model: T5 as a Summarizer\nfrom transformers import T5ForConditionalGeneration\n\ngenerator_checkpoint = 't5-base'\ngenerator = T5ForConditionalGeneration.from_pretrained(generator_checkpoint, max_length = 256).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:57:42.171011Z","iopub.execute_input":"2023-05-03T14:57:42.171372Z","iopub.status.idle":"2023-05-03T14:57:49.528111Z","shell.execute_reply.started":"2023-05-03T14:57:42.171332Z","shell.execute_reply":"2023-05-03T14:57:49.527006Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cc5258de23d492c8a373d371c34f1b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a20e7178e33b47ef815a03389a53ca43"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Loss and Optimisers","metadata":{}},{"cell_type":"code","source":"# Binary Cross Entropy loss for Discriminator\ndiscriminator_loss_fn = nn.BCELoss()\n# Generator Loss received as an output of T5\n\ngen_lr = 5e-5\ndisc_lr = 2e-4\ngenerator_optimiser = torch.optim.AdamW(generator.parameters(), lr = gen_lr, betas=(0.8, 0.9))\ndiscriminator_optimiser = torch.optim.AdamW(discriminator.parameters(), lr = disc_lr, betas=(0.9, 0.999))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:57:49.529841Z","iopub.execute_input":"2023-05-03T14:57:49.530243Z","iopub.status.idle":"2023-05-03T14:57:49.539372Z","shell.execute_reply.started":"2023-05-03T14:57:49.530202Z","shell.execute_reply":"2023-05-03T14:57:49.538312Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Metrics","metadata":{}},{"cell_type":"code","source":"# ROUGE and BERT\nfrom torchmetrics.text.rouge import ROUGEScore\nfrom torchmetrics.text.bert import BERTScore","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:57:49.541094Z","iopub.execute_input":"2023-05-03T14:57:49.541755Z","iopub.status.idle":"2023-05-03T14:57:49.551406Z","shell.execute_reply.started":"2023-05-03T14:57:49.541713Z","shell.execute_reply":"2023-05-03T14:57:49.550380Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Evaluator Model for Semantic Similarity: Bert Large\nfrom transformers import BertModel, BertTokenizerFast\n\nevaluator_checkpoint = 'bert-large-uncased'\nevaluator = BertModel.from_pretrained(evaluator_checkpoint).to(device)\nevaluator_tokenizer = BertTokenizerFast.from_pretrained(\n    evaluator_checkpoint,\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:57:49.552929Z","iopub.execute_input":"2023-05-03T14:57:49.553288Z","iopub.status.idle":"2023-05-03T14:58:24.829226Z","shell.execute_reply.started":"2023-05-03T14:57:49.553252Z","shell.execute_reply":"2023-05-03T14:58:24.828176Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67e905533b1e4a5b80e6194c4d0cbaf4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b0ec03ebf954fe6a4ec962580f07dec"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55d10cedd49d4230908b66746bbd6215"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"752ce1805757482c9ff0e5b5ac568338"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ce7ff8dbe914b25b2b19b00f543f036"}},"metadata":{}}]},{"cell_type":"code","source":"logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.ERROR)\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n# Training Loop\ndef train(\n    generator,\n    discriminator,\n    discriminator_tokenizer,\n    generator_tokenizer,\n    generator_optimiser,\n    discriminator_optimiser,\n    train_loader,\n    epoch\n) -> None:\n    \n    generator.train()\n    discriminator.train()\n    start_time = time.time()\n    log_interval = 5\n    \n    for i, batch in enumerate(train_loader):\n        # DISCRIMINATOR TRAIN STEP\n        # discriminator training on real summary\n        discriminator_optimiser.zero_grad()\n        full_input = batch['target_text']\n        tokenised = discriminator_tokenizer(text = full_input,\n                                        max_length=256,\n                                        padding='max_length',\n                                        return_tensors='pt',\n                                        truncation=True\n                                       )\n        target = torch.ones((len(batch['target_text']), 1), dtype=torch.int32).type(torch.LongTensor).to(device)\n        logits = discriminator(**tokenised.to(device),\n                               labels = target\n                              ).logits\n        prob = torch.sigmoid(logits)\n        loss = discriminator_loss_fn(prob.to('cpu'),\n                                     torch.ones((len(batch['target_text']), 1)))\n        loss.backward()\n        discriminator_optimiser.step()\n        \n        del full_input, tokenised, logits, prob, loss\n        \n        # discriminator training on generated summary\n        discriminator_optimiser.zero_grad()\n        gen_sum = generator.generate(\n            inputs = batch['input']['input_ids'].squeeze(1).detach().to(device),\n            num_beams = 4,\n            top_k = 20,\n            max_length = 256,\n            early_stopping = True,\n            num_return_sequences = 1\n        )\n        gen_sum = generator_tokenizer.batch_decode(\n            gen_sum,\n            skip_special_tokens=False,\n            clean_up_tokenization_spaces=True\n        )\n        full_input = gen_sum\n        tokenised = discriminator_tokenizer(text = full_input,\n                                        max_length=256,\n                                        padding='max_length',\n                                        return_tensors='pt',\n                                        truncation=True\n                                       )\n        target = torch.ones((len(batch['target_text']), 1), dtype=torch.int32).type(torch.LongTensor).to(device)\n        logits = discriminator(**tokenised.to(device),\n                               labels = target\n                              ).logits\n        prob = torch.sigmoid(logits)\n        loss = discriminator_loss_fn(prob.to('cpu'),\n                                     torch.zeros((len(batch['target_text']), 1)))\n        loss.backward()\n        discriminator_optimiser.step()\n        \n        del full_input, tokenised, logits, prob, loss, gen_sum\n        \n        # ADVERSARIAL TRAINING FOR \n        # generator training\n        generator_optimiser.zero_grad()\n        gen_sum = generator.generate(\n            inputs = batch['input']['input_ids'].squeeze(1).detach().to(device),\n            num_beams = 4,\n            top_k = 20,\n            max_length = 256,\n            early_stopping = True,\n            num_return_sequences = 1\n        )\n        gen_sum = generator_tokenizer.batch_decode(\n            gen_sum,\n            skip_special_tokens=False,\n            clean_up_tokenization_spaces=True\n        )\n        full_input = gen_sum\n        tokenised = discriminator_tokenizer(text = full_input,\n                                        max_length=256,\n                                        padding='max_length',\n                                        return_tensors='pt',\n                                        truncation=True\n                                       )\n        target = torch.ones((len(batch['target_text']), 1), dtype=torch.int32).type(torch.LongTensor).to(device)\n        logits = discriminator(**tokenised.to(device),\n                               labels = target\n                              ).logits\n        prob = torch.sigmoid(logits)\n        adv_loss = discriminator_loss_fn(prob.to('cpu'),\n                                     torch.zeros((len(batch['target_text']), 1)))\n        \n        seq2seqloss = generator(\n            input_ids = batch['input']['input_ids'].squeeze(1).to(device),\n            attention_mask = batch['input']['attention_mask'].squeeze(1).to(device),\n            labels = batch['target']['input_ids'].squeeze(1).to(device)\n        ).loss\n        \n        loss = seq2seqloss + adv_loss\n        \n        loss.backward()\n        generator_optimiser.step()\n        \n        del full_input, tokenised, logits, prob, loss, gen_sum\n        \n        if (i+1) % log_interval == 0:\n            # comment if no gpu\n            torch.cuda.empty_cache()\n            gc.collect()\n            \n            s_per_batch = (time.time() - start_time) / log_interval\n            print(f'| epoch {epoch:3d} | {i + 1: 5d} batch | '\n                 f'sec/batch {s_per_batch:5.2f} | ')\n            start_time = time.time()\n            \n#         # TURN OFF TO RESUME NORMAL OPERATION\n#         break\n            \ndef evaluate(\n    model,\n    model_tokenizer,\n    data_loader\n):\n    model.eval()\n    \n    # Initialise metrics\n    rouge = ROUGEScore()\n    bert_score = BERTScore(\n        model_name_or_path = evaluator_checkpoint,\n        model = evaluator.to(device),\n        device = device\n    )\n\n    rogue = rouge.to(device)\n    bert_score = bert_score.to(device)\n    \n    final_bert_score = []\n    \n    start_time = time.time()\n    generation_time = 0\n    rouge_time = 0\n    bert_score_time = 0\n    \n    log_interval = 5\n    \n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        with torch.no_grad():\n            for i, batch in enumerate(data_loader):\n                gen_time = time.time()\n                output = model.generate(\n                    input_ids = batch['input']['input_ids'].squeeze(1).to(device),\n                    attention_mask = batch['input']['attention_mask'].squeeze(1).to(device),\n                )\n                output = model_tokenizer.batch_decode(\n                    output,\n                    skip_special_tokens=True,\n                    clean_up_tokenization_spaces=True\n                )\n                generation_time += time.time() - gen_time\n\n                score_time = time.time()\n                rouge.update(output, batch['target_text'])\n                rouge_time += time.time() - score_time\n\n                score_time = time.time()\n                score = bert_score(output, batch['target_text'])\n                for scr in score['f1']:\n                    final_bert_score.append(scr)\n\n                bert_score_time += time.time() - score_time\n                \n                if (i+1) % log_interval == 0:\n                    s_per_batch = (time.time() - start_time) / log_interval\n                    print(f'| {i + 1: 5d} batch | '\n                         f'sec/batch {s_per_batch:5.2f} | ')\n                    start_time = time.time()\n\n#                 # TURN OFF TO RESUME NORMAL OPERATION\n#                 break\n\n        final_rouge = rouge.compute()\n        final_bert_score = np.mean(np.array(final_bert_score))\n\n\n        return final_rouge, final_bert_score\n            ","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:58:24.837751Z","iopub.execute_input":"2023-05-03T14:58:24.838614Z","iopub.status.idle":"2023-05-03T14:58:24.868077Z","shell.execute_reply.started":"2023-05-03T14:58:24.838574Z","shell.execute_reply":"2023-05-03T14:58:24.867068Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def model_trainer(\n    generator,\n    discriminator,\n    discriminator_tokenizer,\n    generator_tokenizer,\n    generator_optimiser,\n    discriminator_optimiser,\n    train_loader,\n    test_loader,\n    epochs\n):\n    \n    for epoch in tqdm(range(epochs)):\n        epoch_start_time = time.time()\n        \n        train(\n            generator,\n            discriminator,\n            discriminator_tokenizer,\n            generator_tokenizer,\n            generator_optimiser,\n            discriminator_optimiser,\n            train_loader,\n            epoch\n        )\n        print(\"-----EVALUATION STARTED-----\")\n        rouge, bert_score = evaluate(generator, generator_tokenizer, test_loader)\n        \n        elapsed = time.time() - epoch_start_time\n        \n        print('-' * 100)\n        print(\n            f'| end of epoch {epoch + 1:3d} | time: {elapsed:5.2f}s | '\n            f'Rouge1 {rouge[\"rouge1_fmeasure\"].item():4.4f} | Rouge2 {rouge[\"rouge2_fmeasure\"].item():4.4f} | '\n            f'RougeL {rouge[\"rougeL_fmeasure\"].item():4.4f} | RougeL Sum {rouge[\"rougeLsum_fmeasure\"].item():4.4f} | '\n            f'BERT Score {float(bert_score.squeeze()):4.4f}'\n             )\n        print('-' * 100)\n        \n        generator.save_pretrained('/kaggle/working/model' + str(epoch), from_pt=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:58:24.869420Z","iopub.execute_input":"2023-05-03T14:58:24.869898Z","iopub.status.idle":"2023-05-03T14:58:24.881824Z","shell.execute_reply.started":"2023-05-03T14:58:24.869860Z","shell.execute_reply":"2023-05-03T14:58:24.880697Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Make the Train and Test Loader\ntrain_loader = DataLoader(dataset = train_dataset, batch_size = 4, drop_last=True)\ntest_loader = DataLoader(dataset = test_dataset, batch_size = 16, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:58:24.883578Z","iopub.execute_input":"2023-05-03T14:58:24.883955Z","iopub.status.idle":"2023-05-03T14:58:24.895564Z","shell.execute_reply.started":"2023-05-03T14:58:24.883918Z","shell.execute_reply":"2023-05-03T14:58:24.894541Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Train the model\nn_epochs = 7\n\nmodel_trainer(\n    generator,\n    discriminator,\n    discriminator_tokenizer,\n    tokenizer,\n    generator_optimiser,\n    discriminator_optimiser,\n    train_loader,\n    test_loader,\n    epochs = n_epochs\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:58:24.897234Z","iopub.execute_input":"2023-05-03T14:58:24.897640Z","iopub.status.idle":"2023-05-03T15:56:54.924112Z","shell.execute_reply.started":"2023-05-03T14:58:24.897603Z","shell.execute_reply":"2023-05-03T15:56:54.921733Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26c9d146422c4c52ad75d4f12000968d"}},"metadata":{}},{"name":"stdout","text":"| epoch   0 |     5 batch | sec/batch  3.66 | \n| epoch   0 |    10 batch | sec/batch  3.74 | \n| epoch   0 |    15 batch | sec/batch  4.12 | \n| epoch   0 |    20 batch | sec/batch  4.48 | \n| epoch   0 |    25 batch | sec/batch  4.45 | \n| epoch   0 |    30 batch | sec/batch  4.63 | \n| epoch   0 |    35 batch | sec/batch  4.82 | \n| epoch   0 |    40 batch | sec/batch  6.18 | \n| epoch   0 |    45 batch | sec/batch  6.00 | \n| epoch   0 |    50 batch | sec/batch  6.90 | \n| epoch   0 |    55 batch | sec/batch  8.58 | \n| epoch   0 |    60 batch | sec/batch  8.31 | \n| epoch   0 |    65 batch | sec/batch  9.36 | \n| epoch   0 |    70 batch | sec/batch  9.49 | \n| epoch   0 |    75 batch | sec/batch  8.24 | \n-----EVALUATION STARTED-----\n|     5 batch | sec/batch  5.16 | \n|    10 batch | sec/batch  4.96 | \n|    15 batch | sec/batch  4.94 | \n----------------------------------------------------------------------------------------------------\n| end of epoch   1 | time: 554.94s | Rouge1 0.0063 | Rouge2 0.0028 | RougeL 0.0047 | RougeL Sum 0.0047 | BERT Score 0.0092\n----------------------------------------------------------------------------------------------------\n| epoch   1 |     5 batch | sec/batch  9.79 | \n| epoch   1 |    10 batch | sec/batch  8.14 | \n| epoch   1 |    15 batch | sec/batch  9.77 | \n| epoch   1 |    20 batch | sec/batch  8.85 | \n| epoch   1 |    25 batch | sec/batch  6.32 | \n| epoch   1 |    30 batch | sec/batch  7.93 | \n| epoch   1 |    35 batch | sec/batch  7.64 | \n| epoch   1 |    40 batch | sec/batch  6.55 | \n| epoch   1 |    45 batch | sec/batch  7.23 | \n| epoch   1 |    50 batch | sec/batch  6.68 | \n| epoch   1 |    55 batch | sec/batch  7.37 | \n| epoch   1 |    60 batch | sec/batch  6.69 | \n| epoch   1 |    65 batch | sec/batch  5.98 | \n| epoch   1 |    70 batch | sec/batch  6.43 | \n| epoch   1 |    75 batch | sec/batch  6.78 | \n-----EVALUATION STARTED-----\n|     5 batch | sec/batch  4.84 | \n|    10 batch | sec/batch  3.71 | \n|    15 batch | sec/batch  4.14 | \n----------------------------------------------------------------------------------------------------\n| end of epoch   2 | time: 635.70s | Rouge1 0.3470 | Rouge2 0.1486 | RougeL 0.2604 | RougeL Sum 0.2585 | BERT Score 0.5617\n----------------------------------------------------------------------------------------------------\n| epoch   2 |     5 batch | sec/batch  7.21 | \n| epoch   2 |    10 batch | sec/batch  5.19 | \n| epoch   2 |    15 batch | sec/batch  5.71 | \n| epoch   2 |    20 batch | sec/batch  5.51 | \n| epoch   2 |    25 batch | sec/batch  5.19 | \n| epoch   2 |    30 batch | sec/batch  5.38 | \n| epoch   2 |    35 batch | sec/batch  5.49 | \n| epoch   2 |    40 batch | sec/batch  7.58 | \n| epoch   2 |    45 batch | sec/batch  6.02 | \n| epoch   2 |    50 batch | sec/batch  5.65 | \n| epoch   2 |    55 batch | sec/batch  5.84 | \n| epoch   2 |    60 batch | sec/batch  6.23 | \n| epoch   2 |    65 batch | sec/batch  4.82 | \n| epoch   2 |    70 batch | sec/batch  5.15 | \n| epoch   2 |    75 batch | sec/batch  5.07 | \n-----EVALUATION STARTED-----\n|     5 batch | sec/batch  3.00 | \n|    10 batch | sec/batch  2.98 | \n|    15 batch | sec/batch  2.95 | \n----------------------------------------------------------------------------------------------------\n| end of epoch   3 | time: 484.68s | Rouge1 0.3860 | Rouge2 0.1737 | RougeL 0.2832 | RougeL Sum 0.2835 | BERT Score 0.5771\n----------------------------------------------------------------------------------------------------\n| epoch   3 |     5 batch | sec/batch  5.23 | \n| epoch   3 |    10 batch | sec/batch  5.55 | \n| epoch   3 |    15 batch | sec/batch  4.98 | \n| epoch   3 |    20 batch | sec/batch  5.10 | \n| epoch   3 |    25 batch | sec/batch  5.14 | \n| epoch   3 |    30 batch | sec/batch  5.68 | \n| epoch   3 |    35 batch | sec/batch  5.53 | \n| epoch   3 |    40 batch | sec/batch  6.92 | \n| epoch   3 |    45 batch | sec/batch  6.12 | \n| epoch   3 |    50 batch | sec/batch  6.12 | \n| epoch   3 |    55 batch | sec/batch  5.02 | \n| epoch   3 |    60 batch | sec/batch  5.56 | \n| epoch   3 |    65 batch | sec/batch  4.91 | \n| epoch   3 |    70 batch | sec/batch  5.14 | \n| epoch   3 |    75 batch | sec/batch  5.09 | \n-----EVALUATION STARTED-----\n|     5 batch | sec/batch  2.87 | \n|    10 batch | sec/batch  2.97 | \n|    15 batch | sec/batch  3.21 | \n----------------------------------------------------------------------------------------------------\n| end of epoch   4 | time: 465.03s | Rouge1 0.4050 | Rouge2 0.1844 | RougeL 0.2928 | RougeL Sum 0.2919 | BERT Score 0.5895\n----------------------------------------------------------------------------------------------------\n| epoch   4 |     5 batch | sec/batch  5.07 | \n| epoch   4 |    10 batch | sec/batch  5.67 | \n| epoch   4 |    15 batch | sec/batch  5.39 | \n| epoch   4 |    20 batch | sec/batch  4.88 | \n| epoch   4 |    25 batch | sec/batch  4.91 | \n| epoch   4 |    30 batch | sec/batch  5.34 | \n| epoch   4 |    35 batch | sec/batch  5.50 | \n| epoch   4 |    40 batch | sec/batch  6.17 | \n| epoch   4 |    45 batch | sec/batch  5.42 | \n| epoch   4 |    50 batch | sec/batch  5.85 | \n| epoch   4 |    55 batch | sec/batch  5.08 | \n| epoch   4 |    60 batch | sec/batch  6.21 | \n| epoch   4 |    65 batch | sec/batch  4.88 | \n| epoch   4 |    70 batch | sec/batch  5.12 | \n| epoch   4 |    75 batch | sec/batch  5.14 | \n-----EVALUATION STARTED-----\n|     5 batch | sec/batch  3.04 | \n|    10 batch | sec/batch  2.96 | \n|    15 batch | sec/batch  3.44 | \n----------------------------------------------------------------------------------------------------\n| end of epoch   5 | time: 461.42s | Rouge1 0.4238 | Rouge2 0.1967 | RougeL 0.3101 | RougeL Sum 0.3099 | BERT Score 0.5960\n----------------------------------------------------------------------------------------------------\n| epoch   5 |     5 batch | sec/batch  5.48 | \n| epoch   5 |    10 batch | sec/batch  5.09 | \n| epoch   5 |    15 batch | sec/batch  4.82 | \n| epoch   5 |    20 batch | sec/batch  5.04 | \n| epoch   5 |    25 batch | sec/batch  5.09 | \n| epoch   5 |    30 batch | sec/batch  5.15 | \n| epoch   5 |    35 batch | sec/batch  5.68 | \n| epoch   5 |    40 batch | sec/batch  5.82 | \n| epoch   5 |    45 batch | sec/batch  5.42 | \n| epoch   5 |    50 batch | sec/batch  5.74 | \n| epoch   5 |    55 batch | sec/batch  5.19 | \n| epoch   5 |    60 batch | sec/batch  5.33 | \n| epoch   5 |    65 batch | sec/batch  5.08 | \n| epoch   5 |    70 batch | sec/batch  5.78 | \n| epoch   5 |    75 batch | sec/batch  4.93 | \n-----EVALUATION STARTED-----\n|     5 batch | sec/batch  2.84 | \n|    10 batch | sec/batch  3.12 | \n|    15 batch | sec/batch  2.84 | \n----------------------------------------------------------------------------------------------------\n| end of epoch   6 | time: 451.24s | Rouge1 0.4290 | Rouge2 0.2041 | RougeL 0.3155 | RougeL Sum 0.3147 | BERT Score 0.5963\n----------------------------------------------------------------------------------------------------\n| epoch   6 |     5 batch | sec/batch  5.45 | \n| epoch   6 |    10 batch | sec/batch  4.69 | \n| epoch   6 |    15 batch | sec/batch  4.91 | \n| epoch   6 |    20 batch | sec/batch  4.83 | \n| epoch   6 |    25 batch | sec/batch  4.83 | \n| epoch   6 |    30 batch | sec/batch  5.29 | \n| epoch   6 |    35 batch | sec/batch  5.31 | \n| epoch   6 |    40 batch | sec/batch  5.78 | \n| epoch   6 |    45 batch | sec/batch  5.45 | \n| epoch   6 |    50 batch | sec/batch  5.35 | \n| epoch   6 |    55 batch | sec/batch  5.61 | \n| epoch   6 |    60 batch | sec/batch  5.63 | \n| epoch   6 |    65 batch | sec/batch  5.27 | \n| epoch   6 |    70 batch | sec/batch  4.88 | \n| epoch   6 |    75 batch | sec/batch  5.31 | \n-----EVALUATION STARTED-----\n|     5 batch | sec/batch  2.89 | \n|    10 batch | sec/batch  3.37 | \n|    15 batch | sec/batch  3.08 | \n----------------------------------------------------------------------------------------------------\n| end of epoch   7 | time: 448.13s | Rouge1 0.4361 | Rouge2 0.2112 | RougeL 0.3234 | RougeL Sum 0.3227 | BERT Score 0.5999\n----------------------------------------------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"generator.save_pretrained('/kaggle/working/generator_final', from_pt=True)\ndiscriminator.save_pretrained('/kaggle/working/discriminator_final', from_pt=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T16:08:05.904757Z","iopub.execute_input":"2023-05-03T16:08:05.905167Z","iopub.status.idle":"2023-05-03T16:08:09.454386Z","shell.execute_reply.started":"2023-05-03T16:08:05.905131Z","shell.execute_reply":"2023-05-03T16:08:09.453008Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-05-03T16:06:50.343939Z","iopub.execute_input":"2023-05-03T16:06:50.345026Z","iopub.status.idle":"2023-05-03T16:06:50.951923Z","shell.execute_reply.started":"2023-05-03T16:06:50.344987Z","shell.execute_reply":"2023-05-03T16:06:50.950668Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"3730"},"metadata":{}}]},{"cell_type":"markdown","source":"## Results and Examples from here on","metadata":{}},{"cell_type":"code","source":"def get_discriminator(batch):\n    discriminator.eval()\n    with torch.no_grad():\n        full_input = batch['target_text']\n        tokenised = discriminator_tokenizer(text = full_input,\n                                        max_length=256,\n                                        padding='max_length',\n                                        return_tensors='pt',\n                                        truncation=True\n                                       )\n        logits1 = discriminator(**tokenised.to(device),\n#                                        labels = target\n                                      ).logits\n        \n        gen_sum = generator.generate(\n            inputs = batch['input']['input_ids'].squeeze(1).detach().to(device),\n            num_beams = 4,\n            top_k = 20,\n            max_length = 256,\n            early_stopping = True,\n            num_return_sequences = 1\n        )\n        gen_sum = tokenizer.batch_decode(\n            gen_sum,\n            skip_special_tokens=False,\n            clean_up_tokenization_spaces=True\n        )\n#         full_input = [batch['input_text'][i] + gen_sum[i] for i in range(len(batch['target_text']))]\n        full_input = gen_sum\n        tokenised = discriminator_tokenizer(text = full_input,\n                                        max_length=256,\n                                        padding='max_length',\n                                        return_tensors='pt',\n                                        truncation=True\n                                       )\n        logits2 = discriminator(**tokenised.to(device),\n#                                        labels = target\n                                      ).logits\n        \n        return logits1, logits2","metadata":{"execution":{"iopub.status.busy":"2023-05-03T15:57:37.598603Z","iopub.execute_input":"2023-05-03T15:57:37.599792Z","iopub.status.idle":"2023-05-03T15:57:37.610579Z","shell.execute_reply.started":"2023-05-03T15:57:37.599732Z","shell.execute_reply":"2023-05-03T15:57:37.609556Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def get_generated_summary(batch):\n    generator.eval()\n    with torch.no_grad():\n        output = generator.generate(\n            input_ids = batch['input']['input_ids'].squeeze(1).to(device),\n            attention_mask = batch['input']['attention_mask'].squeeze(1).to(device),\n    #                     num_beams = 4,\n    #                     top_k = 20,\n    #                     max_length = 256,\n    #                     early_stopping = True,\n    #                     num_return_sequences = 1\n        )\n        output = tokenizer.batch_decode(\n            output,\n            skip_special_tokens=True,\n            clean_up_tokenization_spaces=True\n        )\n\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-05-03T15:57:42.762582Z","iopub.execute_input":"2023-05-03T15:57:42.762965Z","iopub.status.idle":"2023-05-03T15:57:42.769603Z","shell.execute_reply.started":"2023-05-03T15:57:42.762931Z","shell.execute_reply":"2023-05-03T15:57:42.768385Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"After lr finetune, 7 epochs","metadata":{}},{"cell_type":"code","source":"i = 1\nprint(train_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(train_dataset[i]))\nprint()\nprint(train_dataset[i]['target_text'])\nprint(get_discriminator(train_dataset[i]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T15:58:05.106223Z","iopub.execute_input":"2023-05-03T15:58:05.106729Z","iopub.status.idle":"2023-05-03T15:58:08.941302Z","shell.execute_reply.started":"2023-05-03T15:58:05.106688Z","shell.execute_reply":"2023-05-03T15:58:08.940026Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"excellent executive decision trump wants to cancel air force one order from boeing. build it in mexico it will be cheaper that way trump wants to cancel air force one order from boeing. when did republicans become so fond of regulation trump wants 2cancel air force one order from boeing. trump lies again says jet costs more than 4 billion amp wants to cancel air force one order from boeing. trump lies again says jet costs more than 4 billion amp wants to cancel air force one order from boeing. presidentelect realdonaldtrump wants to cancel a government order for a new air force one. amazing leadership and not even sworn in trump wants to cancel air force one order from boeing. trump wants to cancel air force one order from boeing what about the money for security at trump tower\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/generation/utils.py:1292: UserWarning: Using `max_length`'s default (256) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n  UserWarning,\n","output_type":"stream"},{"name":"stdout","text":"['the paragraphs report on presidentelect trumps decision to cancel an order for a new air force one from boeing which is a good executive decision and a good example of the importance of executive discretion in the government some articles mention the lack of funding for security at trump towers and the lack of transparency in the government the tone is critical of trumps decision and the potential impact on the economy']\n\ndonald trump wants to cancel the order for a new air force one from boeing claiming it is too expensive over 4 billion and suggesting building it in mexico would be cheaper he also suggests using his own jet and charging taxpayers there are criticisms of his decision including concerns about security at trump tower and the accuracy of his cost estimates\n(tensor([[10.2265]], device='cuda:0'), tensor([[-10.1844]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 25\nprint(train_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(train_dataset[i]))\nprint()\nprint(train_dataset[i]['target_text'])\nprint(get_discriminator(train_dataset[i]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T15:59:00.355959Z","iopub.execute_input":"2023-05-03T15:59:00.356640Z","iopub.status.idle":"2023-05-03T15:59:02.417954Z","shell.execute_reply.started":"2023-05-03T15:59:00.356600Z","shell.execute_reply":"2023-05-03T15:59:02.416632Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"remarkable photos from nytimes the year in pictures 2016. this is excellent the year in pictures 2016. a year to be confounded shocked nytimes year in pictures 2016. some extraordinary photos here the nytimes year in pictures 2016. the year in pictures 2016 new york times. a treasure here gt gt the year in pictures 2016. a riveting curation the year in pictures 2016. what a year 2016 even tragedy can be captured beautifully the year in pictures 2016\n\n['the new york times has published a collection of extraordinary photos highlighting the year in pictures 2016 the collection includes some of the best photos from the year even tragedy can be captured beautifully the collection includes some of the best photos from the year even though some have been criticized for their coverage the collection is a treasure trove of extraordinary photos from the new york times and other sources']\n\nthe new york times the year in pictures 2016 is a collection of remarkable and extraordinary photographs that capture the tragedies and triumphs of the year many people found the curation to be a riveting and beautiful depiction of a year that left people confounded and shocked the photos are described as a treasure and a great piece and they demonstrate that even in tragedy beauty can be found\n(tensor([[10.2367]], device='cuda:0'), tensor([[-10.1853]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 4\nprint(train_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(train_dataset[i]))\nprint()\nprint(train_dataset[i]['target_text'])\nprint(get_discriminator(train_dataset[i]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T15:59:48.523607Z","iopub.execute_input":"2023-05-03T15:59:48.523997Z","iopub.status.idle":"2023-05-03T15:59:52.116355Z","shell.execute_reply.started":"2023-05-03T15:59:48.523963Z","shell.execute_reply":"2023-05-03T15:59:52.114899Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"the new york times how to pounce on best credit card offers. how to pounce on best credit card offers before banks pull them. how to search for the best credit card deals before the disappear. how to pounce on best credit card offers last chance for freemoney just pick it up. 1500 in your pocket ronlieber explains how to pounce on the best credit card offers. how to pounce on best credit card offers por ron lieber en nyt. how to pounce on best credit card offers by ron lieber the new york times. new york times most viewed stories how to pounce on best credit card offers\n\n['the new york times has compiled a list of tips on how to pounce on credit card offers before they disappear the list includes tips on how to search for the best credit card deals before banks pull them some articles have been viewed by thousands of people including ron lieber some articles have been criticized for not pinning on the best credit card offers while others have criticized the lack of transparency in the credit card industry']\n\nthe article discusses how to take advantage of credit card offers before they expire and how to search for the best deals ron lieber explains how to earn free money by pouncing on credit card offers and the article is one of the most viewed stories on the new york times website\n(tensor([[10.2226]], device='cuda:0'), tensor([[-10.1752]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 9\nprint(train_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(train_dataset[i]))\nprint()\nprint(train_dataset[i]['target_text'])\nprint(get_discriminator(train_dataset[i]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T16:00:33.524638Z","iopub.execute_input":"2023-05-03T16:00:33.525354Z","iopub.status.idle":"2023-05-03T16:00:35.423010Z","shell.execute_reply.started":"2023-05-03T16:00:33.525315Z","shell.execute_reply":"2023-05-03T16:00:35.421008Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"38 dead and 155 wounded in twin bomb attack near istanbul stadium who is really behind this atta. 29 dead and 166 wounded in twin bomb attack near istanbul stadium. terror in istanbul 29 dead 166 wounded in twin bomb attack in turkey. thoughts and prayers to the victims 38 dead and 155 wounded in twin bomb attack near istanbul stadium foxnews. 15 dead 69 wounded in twin bomb attack in istanbul. thoughts and prayers to the victims 38 dead and 155 wounded in twin bomb attack near istanbul stadium foxnews. 38 dead and 155 wounded in twin bomb attack near istanbul stadium what goes around comes around. 38 dead and 155 wounded in twin bomb attack near istanbul stadium what goes around comes around\n\n['the paragraphs report on a twin bomb attack near an istanbul stadium that left 38 people dead and 155 wounded the focus is on the attack and the potential for further violence in turkey with coverage highlighting the reporting by fox news and other sources']\n\na twin bomb attack near an istanbul stadium has resulted in 38 dead and 155 wounded the attack has been widely condemned and thoughts and prayers are with the victims there are no clear indications yet as to who is responsible for the attack\n(tensor([[10.2298]], device='cuda:0'), tensor([[-10.1888]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 15\nprint(train_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(train_dataset[i]))\nprint()\nprint(train_dataset[i]['target_text'])\nprint(get_discriminator(train_dataset[i]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T16:01:33.372129Z","iopub.execute_input":"2023-05-03T16:01:33.373185Z","iopub.status.idle":"2023-05-03T16:01:36.047450Z","shell.execute_reply.started":"2023-05-03T16:01:33.373140Z","shell.execute_reply":"2023-05-03T16:01:36.046305Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"at least 27 people killed and 57 others wounded when blasts went off near car spare parts shops in al sinak. two blasts in central baghdad kill at least 28. double bomb attack hits al sinak market at least 21 killed and dozens wounded as blasts triggered by. at least 18 killed as bomb attacks rock central baghdad ajenglish. at least 21 killed and dozens wounded as blasts triggered by suicide bomber and explosive ajenglish. 2 blasts in central baghdad kill at least 18 police say afp al jazeera. dozens also injured as two bombs explode at busy market in central al sinak neighbourhood. at least 21 killed and dozens wounded in baghdad after a suicide bombing\n\n['two bombs explode at a busy market in central baghdad causing at least 27 people to be killed and 57 others to be wounded the explosions occurred near car spare parts shops and in the market the explosions were triggered by a suicide bomber and an explosive the incident has been widely reported in the news with some expressing shock and horror at the incident']\n\ntwo blasts in central baghdad specifically in the al sinak market resulted in the deaths of at least 27 people and wounded 57 others the explosions occurred near car spare parts shops and were triggered by a suicide bomber and an explosive the attack took place in a crowded market causing dozens of injuries the death toll was later updated to at least 28 people the blasts were part of a series of bombings in central baghdad resulting in the deaths of at least 18 people\n(tensor([[10.2325]], device='cuda:0'), tensor([[-10.1880]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 78\nprint(train_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(train_dataset[i]))\nprint()\nprint(train_dataset[i]['target_text'])\nprint(get_discriminator(train_dataset[i]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T16:02:18.883380Z","iopub.execute_input":"2023-05-03T16:02:18.884099Z","iopub.status.idle":"2023-05-03T16:02:21.153335Z","shell.execute_reply.started":"2023-05-03T16:02:18.884057Z","shell.execute_reply":"2023-05-03T16:02:21.152171Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"delta bans disruptive trump supporter for life after pro trumpantihillary tirade video goes viral. bravo delta delta air lines bans disruptive donald trump supporter for life. loud rude and disrespectful was it actually trump they banned delta bans disruptive trump supporter for life. delta air lines bans disruptive donald trump supporter for life thankyou delta. delta air lines bans disruptive donald trump supporter for life bravo delta airlines. delta air lines bans disruptive donald trump supporter for life new york times. well done delta delta air lines bans disruptive donald trump supporter for life. fair treatment for all delta air lines bans disruptive donald trump supporter for life\n\n['delta air lines has banned a disruptive donald trump supporter from flying for life after a video of the supporter expressing a protrump antihillary tirade went viral the incident has been widely reported and has been widely criticized with some expressing support for the president and others expressing concern about the impact of the incident on the country']\n\ndelta air lines has banned a disruptive donald trump supporter from flying for life after a video of the individuals protrump and antihillary tirade went viral on social media the incident has gained attention in the media with many expressing support for deltas decision and criticizing the individuals behavior on the flight some have also raised concerns about the impact of political polarization and the role of social media in shaping public opinion and discourse\n(tensor([[10.2414]], device='cuda:0'), tensor([[-10.1871]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 150\nprint(train_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(train_dataset[i]))\nprint()\nprint(train_dataset[i]['target_text'])\nprint(get_discriminator(train_dataset[i]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T16:03:16.389823Z","iopub.execute_input":"2023-05-03T16:03:16.390305Z","iopub.status.idle":"2023-05-03T16:03:19.439851Z","shell.execute_reply.started":"2023-05-03T16:03:16.390263Z","shell.execute_reply":"2023-05-03T16:03:19.438642Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"swap rail car for bus it is a holocaust shameful syrians in rebel areas doom or the green bus. must ready by abarnardnyt and hwaida_saad stark choice for syrians in rebel areas doom or the green bus. latest news update from luisa florez stark choice for syrians in rebel areas doom or the green bus. imagine facing this choice with your family stark choice for syrians in rebel areas doom or the green bus. latest news update from luisa florez stark choice for syrians in rebel areas doom or the green bus. swap rail car for bus it is a holocaust shameful syrians in rebel areas doom or the green bus. stark choice for syrians in rebel areas doom or the green bus check out via nyt the new york times. sad piece about syria though beautifully written stark choice 4syrians in rebel areas doom or the green bus\n\n['the paragraphs report on a stark choice for syrians in rebel areas facing doom or the green bus the focus is on the piece by luisa florez and her commentary on the issue with some expressing sadness and others expressing concern about the potential consequences of the conflict the focus is on the piece and its implications for syrians in rebel areas']\n\nthe article discusses the stark choice faced by syrians in rebel areas between staying and facing possible doom or taking the green bus and leaving the situation is described as a holocaust and the emotional impact of this decision on families is highlighted the reporting is empathetic and heartbreaking with no particular agenda and is praised as beautifully written the article is widely shared and recommended\n(tensor([[10.2387]], device='cuda:0'), tensor([[-10.1839]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 257\nprint(train_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(train_dataset[i]))\nprint()\nprint(train_dataset[i]['target_text'])\nprint(get_discriminator(train_dataset[i]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T16:04:15.501856Z","iopub.execute_input":"2023-05-03T16:04:15.502594Z","iopub.status.idle":"2023-05-03T16:04:17.850114Z","shell.execute_reply.started":"2023-05-03T16:04:15.502551Z","shell.execute_reply":"2023-05-03T16:04:17.848824Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"huge victory standingrock water safety nativeamerican dakotaaccesspipeline army corps not grant easement. army corps denies easement for dakota access pipeline crossing. army corps denies easement for dakotaaccesspipeline crossing abc news. the department of the army will not approve an easement that would have allowed the proposed dakota access pipeline to cross under lake oahe in north dakota the armys assistant secretary for civil works announced today in a statementthe army claimed in a statement that assistant secretary for. the department of the army will not approve an easement that would have allowed the proposed dakota access pipeline to cross under lake oahe in north dakota the armys assistant secretary for civil works announced today in a statementthe army claimed in a statement that assistant secretary for. army corps denies easement for dakota access pipeline crossing. one small step army corps denies easement for dakota access pipeline crossing. army corps denies easement for dakota access pipeline crossing you are out of touch\n\n['the paragraphs report on the decision by the army corps to deny an easement for the dakota access pipeline to cross under lake oahe in north dakota the decision is a huge victory for standingrock water safety nativeamerican standingrock and the armys assistant secretary for civil works announced the decision today']\n\nthe paragraphs report on the decision by the us army corps of engineers to deny an easement for the dakota access pipeline to cross under lake oahe in north dakota which is considered a huge victory for standing rock sioux tribe and activists concerned about water safety and native american rights some articles mention the armys announcement and the potential implications of the decision while others express support for the decision and criticize those who oppose it overall the tone is celebratory and hopeful for the future of the environment and indigenous communities\n(tensor([[10.2418]], device='cuda:0'), tensor([[-10.1589]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"code","source":"# Never Seen Before\ni = 300\nprint(train_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(train_dataset[i]))\nprint()\nprint(train_dataset[i]['target_text'])\nprint(get_discriminator(train_dataset[i]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T16:05:13.850744Z","iopub.execute_input":"2023-05-03T16:05:13.851838Z","iopub.status.idle":"2023-05-03T16:05:16.042585Z","shell.execute_reply.started":"2023-05-03T16:05:13.851783Z","shell.execute_reply":"2023-05-03T16:05:16.041329Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"authorities found a sixth survivor the man was found under the fuselage officials forcachapecoense ht. colombia plane crash 75 dead some survivors. 6 possible survivors in colombia plane accident officials say. 6 possible survivors in colombia plane accident officials say. colombia plane crash 6th survivor found cnn. cnnbrk authorities find a sixth survivor of a plane crash in colombia the man was found under the fuselage of. colombia plane crash 6th survivor found estimated 75 killed. black boxes from plane that crashed in colombia have been found according to civil aviation authority\n\n['the paragraphs report on a plane crash in colombia that left 75 people dead and six possible survivors with one man found under the fuselage the article notes that black boxes from the plane that crashed in colombia have been found and the number of survivors is estimated at around six the article notes that the man was found under the fuselage and that the crash was a tragic event with some expressing shock and sadness at the news']\n\nauthorities found a sixth survivor from the colombia plane crash in which 75 people were killed the man was found under the fuselage and there were initially six possible survivors according to officials the black boxes from the plane have been found and the civil aviation authority confirms that 76 people are dead the survivor was a member of the brazilian soccer team that was traveling on the plane\n(tensor([[10.2399]], device='cuda:0'), tensor([[-10.1861]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"After lr finetune, discriminator correction","metadata":{}},{"cell_type":"code","source":"i = 1\nprint(train_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(train_dataset[i]))\nprint()\nprint(train_dataset[i]['target_text'])\nprint(get_discriminator(train_dataset[i]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:37:31.855084Z","iopub.execute_input":"2023-05-03T14:37:31.855845Z","iopub.status.idle":"2023-05-03T14:37:33.785438Z","shell.execute_reply.started":"2023-05-03T14:37:31.855808Z","shell.execute_reply":"2023-05-03T14:37:33.784218Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"excellent executive decision trump wants to cancel air force one order from boeing. build it in mexico it will be cheaper that way trump wants to cancel air force one order from boeing. when did republicans become so fond of regulation trump wants 2cancel air force one order from boeing. trump lies again says jet costs more than 4 billion amp wants to cancel air force one order from boeing. trump lies again says jet costs more than 4 billion amp wants to cancel air force one order from boeing. presidentelect realdonaldtrump wants to cancel a government order for a new air force one. amazing leadership and not even sworn in trump wants to cancel air force one order from boeing. trump wants to cancel air force one order from boeing what about the money for security at trump tower\n\n['the paragraphs report on presidentelect trumps decision to cancel an air force one order from boeing the focus is on the executive decision and the potential impact on security at trump tower the focus is on the executive decision and the potential impact on security at trump tower']\n\ndonald trump wants to cancel the order for a new air force one from boeing claiming it is too expensive over 4 billion and suggesting building it in mexico would be cheaper he also suggests using his own jet and charging taxpayers there are criticisms of his decision including concerns about security at trump tower and the accuracy of his cost estimates\n(tensor([[9.8521]], device='cuda:0'), tensor([[-9.7622]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 25\nprint(train_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(train_dataset[i]))\nprint()\nprint(train_dataset[i]['target_text'])\nprint(get_discriminator(train_dataset[i]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:37:38.131193Z","iopub.execute_input":"2023-05-03T14:37:38.131789Z","iopub.status.idle":"2023-05-03T14:37:39.940411Z","shell.execute_reply.started":"2023-05-03T14:37:38.131745Z","shell.execute_reply":"2023-05-03T14:37:39.939114Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"remarkable photos from nytimes the year in pictures 2016. this is excellent the year in pictures 2016. a year to be confounded shocked nytimes year in pictures 2016. some extraordinary photos here the nytimes year in pictures 2016. the year in pictures 2016 new york times. a treasure here gt gt the year in pictures 2016. a riveting curation the year in pictures 2016. what a year 2016 even tragedy can be captured beautifully the year in pictures 2016\n\n['the new york times has published a year in pictures 2016 with some remarkable photos from the coverage including some from the new york times and others']\n\nthe new york times the year in pictures 2016 is a collection of remarkable and extraordinary photographs that capture the tragedies and triumphs of the year many people found the curation to be a riveting and beautiful depiction of a year that left people confounded and shocked the photos are described as a treasure and a great piece and they demonstrate that even in tragedy beauty can be found\n(tensor([[9.8505]], device='cuda:0'), tensor([[-9.8530]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 4\nprint(train_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(train_dataset[i]))\nprint()\nprint(train_dataset[i]['target_text'])\nprint(get_discriminator(train_dataset[i]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:37:44.238564Z","iopub.execute_input":"2023-05-03T14:37:44.239399Z","iopub.status.idle":"2023-05-03T14:37:45.787991Z","shell.execute_reply.started":"2023-05-03T14:37:44.239349Z","shell.execute_reply":"2023-05-03T14:37:45.786846Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"the new york times how to pounce on best credit card offers. how to pounce on best credit card offers before banks pull them. how to search for the best credit card deals before the disappear. how to pounce on best credit card offers last chance for freemoney just pick it up. 1500 in your pocket ronlieber explains how to pounce on the best credit card offers. how to pounce on best credit card offers por ron lieber en nyt. how to pounce on best credit card offers by ron lieber the new york times. new york times most viewed stories how to pounce on best credit card offers\n\n['the article discusses how to search for the best credit card offers before banks pull them out the article has been widely viewed and has garnered attention from readers and other sources']\n\nthe article discusses how to take advantage of credit card offers before they expire and how to search for the best deals ron lieber explains how to earn free money by pouncing on credit card offers and the article is one of the most viewed stories on the new york times website\n(tensor([[9.8478]], device='cuda:0'), tensor([[-9.8532]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 9\nprint(train_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(train_dataset[i]))\nprint()\nprint(train_dataset[i]['target_text'])\nprint(get_discriminator(train_dataset[i]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:37:49.739884Z","iopub.execute_input":"2023-05-03T14:37:49.740938Z","iopub.status.idle":"2023-05-03T14:37:51.116423Z","shell.execute_reply.started":"2023-05-03T14:37:49.740896Z","shell.execute_reply":"2023-05-03T14:37:51.115218Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"38 dead and 155 wounded in twin bomb attack near istanbul stadium who is really behind this atta. 29 dead and 166 wounded in twin bomb attack near istanbul stadium. terror in istanbul 29 dead 166 wounded in twin bomb attack in turkey. thoughts and prayers to the victims 38 dead and 155 wounded in twin bomb attack near istanbul stadium foxnews. 15 dead 69 wounded in twin bomb attack in istanbul. thoughts and prayers to the victims 38 dead and 155 wounded in twin bomb attack near istanbul stadium foxnews. 38 dead and 155 wounded in twin bomb attack near istanbul stadium what goes around comes around. 38 dead and 155 wounded in twin bomb attack near istanbul stadium what goes around comes around\n\n['the paragraphs report on the 38 dead and 155 wounded in a twin bomb attack near istanbul stadium the focus is on the terror attacks perpetrators and their thoughts and prayers']\n\na twin bomb attack near an istanbul stadium has resulted in 38 dead and 155 wounded the attack has been widely condemned and thoughts and prayers are with the victims there are no clear indications yet as to who is responsible for the attack\n(tensor([[9.8457]], device='cuda:0'), tensor([[-9.8535]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 15\nprint(train_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(train_dataset[i]))\nprint()\nprint(train_dataset[i]['target_text'])\nprint(get_discriminator(train_dataset[i]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:37:55.376758Z","iopub.execute_input":"2023-05-03T14:37:55.377457Z","iopub.status.idle":"2023-05-03T14:37:58.206483Z","shell.execute_reply.started":"2023-05-03T14:37:55.377420Z","shell.execute_reply":"2023-05-03T14:37:58.204457Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"at least 27 people killed and 57 others wounded when blasts went off near car spare parts shops in al sinak. two blasts in central baghdad kill at least 28. double bomb attack hits al sinak market at least 21 killed and dozens wounded as blasts triggered by. at least 18 killed as bomb attacks rock central baghdad ajenglish. at least 21 killed and dozens wounded as blasts triggered by suicide bomber and explosive ajenglish. 2 blasts in central baghdad kill at least 18 police say afp al jazeera. dozens also injured as two bombs explode at busy market in central al sinak neighbourhood. at least 21 killed and dozens wounded in baghdad after a suicide bombing\n\n['two bombs explode in central baghdad near car spare parts shops killing at least 28 people and injuring 57 others the explosions occurred near a busy market in al sinak and were triggered by a suicide bomber and explosive the blasts occurred in the central market and were triggered by the suicide bomber and explosive ajenglish the blasts killed at least 21 people and injured dozens more']\n\ntwo blasts in central baghdad specifically in the al sinak market resulted in the deaths of at least 27 people and wounded 57 others the explosions occurred near car spare parts shops and were triggered by a suicide bomber and an explosive the attack took place in a crowded market causing dozens of injuries the death toll was later updated to at least 28 people the blasts were part of a series of bombings in central baghdad resulting in the deaths of at least 18 people\n(tensor([[9.8509]], device='cuda:0'), tensor([[-9.8530]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 78\nprint(test_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(test_dataset[i]))\nprint()\nprint(test_dataset[i]['target_text'])\nprint(get_discriminator(test_dataset[i]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:44:52.875886Z","iopub.execute_input":"2023-05-03T14:44:52.876687Z","iopub.status.idle":"2023-05-03T14:44:54.772531Z","shell.execute_reply.started":"2023-05-03T14:44:52.876648Z","shell.execute_reply":"2023-05-03T14:44:54.771309Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"delta banned racist trumpkin fliyer for life. delta banned racist trumpkin fliyer for life. bravo delta delta air lines bans disruptive donald trump supporter for life. banned and refunded others delta air lines bans disruptive donald trump supporter for life\n\n['delta air lines has banned and refunded others a racist trumpkin fliyer for life and has banned and refunded others the airline has also banned and refunded others the airline has also been criticized for its actions and its handling of the situation']\n\ndelta air lines has banned a disruptive donald trump supporter from flying for life after a video of the individuals protrump and antihillary tirade went viral on social media the incident has gained attention in the media with many expressing support for deltas decision and criticizing the individuals behavior on the flight some have also raised concerns about the impact of political polarization and the role of social media in shaping public opinion and discourse\n(tensor([[9.8516]], device='cuda:0'), tensor([[-9.8539]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 150\nprint(test_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(test_dataset[i]))\nprint()\nprint(test_dataset[i]['target_text'])\nprint(get_discriminator(test_dataset[i]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:49:34.132914Z","iopub.execute_input":"2023-05-03T14:49:34.133360Z","iopub.status.idle":"2023-05-03T14:49:36.144554Z","shell.execute_reply.started":"2023-05-03T14:49:34.133309Z","shell.execute_reply":"2023-05-03T14:49:36.142571Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"heartbreaking empathetic reporting wo an agenda stark choice for syrians in rebel areas doom or the green bus. great story from abarnardnyt et al stark choice for syrians in rebel areas doom or the green bus. heartbreaking empathetic reporting wo an agenda stark choice for syrians in rebel areas doom or the green bus. imagine facing this choice with your family stark choice for syrians in rebel areas doom or the green bus\n\n['the paragraphs report on a heartbreaking and empathetic story about a political agenda that has left many syrians facing a choice between doom and the green bus the focus is on the story and the implications for syrians in rebel areas']\n\nthe article discusses the stark choice faced by syrians in rebel areas between staying and facing possible doom or taking the green bus and leaving the situation is described as a holocaust and the emotional impact of this decision on families is highlighted the reporting is empathetic and heartbreaking with no particular agenda and is praised as beautifully written the article is widely shared and recommended\n(tensor([[9.8510]], device='cuda:0'), tensor([[-9.8529]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 257\nprint(test_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(test_dataset[i]))\nprint()\nprint(test_dataset[i]['target_text'])\nprint(get_discriminator(test_dataset[i]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:52:18.025188Z","iopub.execute_input":"2023-05-03T14:52:18.026045Z","iopub.status.idle":"2023-05-03T14:52:19.698853Z","shell.execute_reply.started":"2023-05-03T14:52:18.026007Z","shell.execute_reply":"2023-05-03T14:52:19.697691Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"army corps says no to dakota access pipeline. show them how it is done army corps denies easement for dakota access pipeline crossing. army corps denies easement for dakota access pipeline crossing amp alternate routes to be examined. one small step army corps denies easement for dakota access pipeline crossing\n\n['the paragraphs report on the army corps denying an easement for the dakota access pipeline crossing and discuss alternate routes to be examined the focus is on the army corps decision to deny the crossing and the importance of showing them how it is done']\n\nthe paragraphs report on the decision by the us army corps of engineers to deny an easement for the dakota access pipeline to cross under lake oahe in north dakota which is considered a huge victory for standing rock sioux tribe and activists concerned about water safety and native american rights some articles mention the armys announcement and the potential implications of the decision while others express support for the decision and criticize those who oppose it overall the tone is celebratory and hopeful for the future of the environment and indigenous communities\n(tensor([[9.8515]], device='cuda:0'), tensor([[-9.8537]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"code","source":"# Never Seen Before Prompt\ni = 300\nprint(test_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(test_dataset[i]))\nprint()\nprint(test_dataset[i]['target_text'])\nprint(get_discriminator(test_dataset[i]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T14:47:47.993688Z","iopub.execute_input":"2023-05-03T14:47:47.994076Z","iopub.status.idle":"2023-05-03T14:47:50.943960Z","shell.execute_reply.started":"2023-05-03T14:47:47.994043Z","shell.execute_reply":"2023-05-03T14:47:50.942678Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"authorities say 76 people are confirmed dead after a plane carrying a soccer team crashed in colombia. brazilian soccer team plane crash 6th survivor found under fuselage. authorities find a sixth survivor from plane crash in colombia the man was found under the fuselage official says. 6 possible survivors in colombia plane accident officials say\n\n['a plane carrying a brazilian soccer team crashed in colombia killing 76 people the man was found under the fuselage and is the sixth person to survive the crash officials say there are no survivors of the crash the crash has been reported by several news outlets including cnn and cnn']\n\nauthorities found a sixth survivor from the colombia plane crash in which 75 people were killed the man was found under the fuselage and there were initially six possible survivors according to officials the black boxes from the plane have been found and the civil aviation authority confirms that 76 people are dead the survivor was a member of the brazilian soccer team that was traveling on the plane\n(tensor([[9.8505]], device='cuda:0'), tensor([[-9.8519]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Initial model with no discriminator","metadata":{}},{"cell_type":"code","source":"i = 1\nprint(train_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(train_dataset[i]))\nprint()\nprint(train_dataset[i]['target_text'])","metadata":{"execution":{"iopub.status.busy":"2023-05-03T13:18:38.620700Z","iopub.execute_input":"2023-05-03T13:18:38.621188Z","iopub.status.idle":"2023-05-03T13:18:40.032286Z","shell.execute_reply.started":"2023-05-03T13:18:38.621148Z","shell.execute_reply":"2023-05-03T13:18:40.031023Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"excellent executive decision trump wants to cancel air force one order from boeing. build it in mexico it will be cheaper that way trump wants to cancel air force one order from boeing. when did republicans become so fond of regulation trump wants 2cancel air force one order from boeing. trump lies again says jet costs more than 4 billion amp wants to cancel air force one order from boeing. trump lies again says jet costs more than 4 billion amp wants to cancel air force one order from boeing. presidentelect realdonaldtrump wants to cancel a government order for a new air force one. amazing leadership and not even sworn in trump wants to cancel air force one order from boeing. trump wants to cancel air force one order from boeing what about the money for security at trump tower\n\n['julian zelizer: trump lies again says jet costs more than 4 billion amp wants to cancel order. zelizer: amazing leadership and not even sworn in trump wants to cancel order from boeing. he says trump lies again says jet costs more than 4 billion amp wants to cancel order. zelizer: trump lies again says jet costs more than 4 billion amp wants to cancel order.']\n\ndonald trump wants to cancel the order for a new air force one from boeing claiming it is too expensive over 4 billion and suggesting building it in mexico would be cheaper he also suggests using his own jet and charging taxpayers there are criticisms of his decision including concerns about security at trump tower and the accuracy of his cost estimates\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 25\nprint(test_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(test_dataset[i]))\nprint()\nprint(test_dataset[i]['target_text'])","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:58:02.537673Z","iopub.execute_input":"2023-05-01T19:58:02.538608Z","iopub.status.idle":"2023-05-01T19:58:03.842799Z","shell.execute_reply.started":"2023-05-01T19:58:02.538566Z","shell.execute_reply":"2023-05-01T19:58:03.841534Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"this is excellent the year in pictures 2016. the year in pictures 2016 new york times. the nyt the year in pictures 2016. such a great piece the year in pictures 2016\n\n[\"aaron carroll: this is excellent the year in pictures 2016. carroll: it's a great piece, and the year in pictures 2016 is a great year. he says the year in pictures 2016 is a great year, and the new york times is great. carroll: the year in pictures 2016 is a great year, and the year in pictures 2016 is a great year.\"]\n\nthe new york times the year in pictures 2016 is a collection of remarkable and extraordinary photographs that capture the tragedies and triumphs of the year many people found the curation to be a riveting and beautiful depiction of a year that left people confounded and shocked the photos are described as a treasure and a great piece and they demonstrate that even in tragedy beauty can be found\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 1\nprint(train_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(train_dataset[i]))\nprint()\nprint(train_dataset[i]['target_text'])","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:45:49.161594Z","iopub.execute_input":"2023-05-01T19:45:49.162552Z","iopub.status.idle":"2023-05-01T19:45:50.557528Z","shell.execute_reply.started":"2023-05-01T19:45:49.162513Z","shell.execute_reply":"2023-05-01T19:45:50.556281Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"excellent executive decision trump wants to cancel air force one order from boeing. build it in mexico it will be cheaper that way trump wants to cancel air force one order from boeing. when did republicans become so fond of regulation trump wants 2cancel air force one order from boeing. trump lies again says jet costs more than 4 billion amp wants to cancel air force one order from boeing. trump lies again says jet costs more than 4 billion amp wants to cancel air force one order from boeing. presidentelect realdonaldtrump wants to cancel a government order for a new air force one. amazing leadership and not even sworn in trump wants to cancel air force one order from boeing. trump wants to cancel air force one order from boeing what about the money for security at trump tower\n\n['julian zelizer: trump lies again says jet costs more than 4 billion amp wants to cancel order. zelizer: amazing leadership and not even sworn in trump wants to cancel order from boeing. he says trump lies again says jet costs more than 4 billion amp wants to cancel order. zelizer: trump lies again says jet costs more than 4 billion amp wants to cancel order.']\n\ndonald trump wants to cancel the order for a new air force one from boeing claiming it is too expensive over 4 billion and suggesting building it in mexico would be cheaper he also suggests using his own jet and charging taxpayers there are criticisms of his decision including concerns about security at trump tower and the accuracy of his cost estimates\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 4\nprint(train_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(train_dataset[i]))\nprint()\nprint(train_dataset[i]['target_text'])","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:46:39.695624Z","iopub.execute_input":"2023-05-01T19:46:39.696053Z","iopub.status.idle":"2023-05-01T19:46:40.692210Z","shell.execute_reply.started":"2023-05-01T19:46:39.696015Z","shell.execute_reply":"2023-05-01T19:46:40.690323Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"the new york times how to pounce on best credit card offers. how to pounce on best credit card offers before banks pull them. how to search for the best credit card deals before the disappear. how to pounce on best credit card offers last chance for freemoney just pick it up. 1500 in your pocket ronlieber explains how to pounce on the best credit card offers. how to pounce on best credit card offers por ron lieber en nyt. how to pounce on best credit card offers by ron lieber the new york times. new york times most viewed stories how to pounce on best credit card offers\n\n[\"the new york times explains how to pounce on the best credit card offers. ron lieber explains how to search for the best credit card deals before they disappear. lieber: i'm a pouncer, and i'm not a pouncer.\"]\n\nthe article discusses how to take advantage of credit card offers before they expire and how to search for the best deals ron lieber explains how to earn free money by pouncing on credit card offers and the article is one of the most viewed stories on the new york times website\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 9\nprint(train_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(train_dataset[i]))\nprint()\nprint(train_dataset[i]['target_text'])","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:49:06.769800Z","iopub.execute_input":"2023-05-01T19:49:06.770845Z","iopub.status.idle":"2023-05-01T19:49:07.740718Z","shell.execute_reply.started":"2023-05-01T19:49:06.770796Z","shell.execute_reply":"2023-05-01T19:49:07.739338Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"38 dead and 155 wounded in twin bomb attack near istanbul stadium who is really behind this atta. 29 dead and 166 wounded in twin bomb attack near istanbul stadium. terror in istanbul 29 dead 166 wounded in twin bomb attack in turkey. thoughts and prayers to the victims 38 dead and 155 wounded in twin bomb attack near istanbul stadium foxnews. 15 dead 69 wounded in twin bomb attack in istanbul. thoughts and prayers to the victims 38 dead and 155 wounded in twin bomb attack near istanbul stadium foxnews. 38 dead and 155 wounded in twin bomb attack near istanbul stadium what goes around comes around. 38 dead and 155 wounded in twin bomb attack near istanbul stadium what goes around comes around\n\n['turkey: 38 dead, 155 wounded in twin bomb attack near istanbul stadium. foxnews: 166 wounded in twin bomb attack near istanbul stadium. foxnews: russian prime minister vladimir putin vladimir putin vladimir putin.']\n\na twin bomb attack near an istanbul stadium has resulted in 38 dead and 155 wounded the attack has been widely condemned and thoughts and prayers are with the victims there are no clear indications yet as to who is responsible for the attack\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 15\nprint(train_dataset[i]['input_text'])\nprint()\nprint(get_generated_summary(train_dataset[i]))\nprint()\nprint(train_dataset[i]['target_text'])","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:52:50.133749Z","iopub.execute_input":"2023-05-01T19:52:50.134259Z","iopub.status.idle":"2023-05-01T19:52:50.917147Z","shell.execute_reply.started":"2023-05-01T19:52:50.134216Z","shell.execute_reply":"2023-05-01T19:52:50.916023Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"at least 27 people killed and 57 others wounded when blasts went off near car spare parts shops in al sinak. two blasts in central baghdad kill at least 28. double bomb attack hits al sinak market at least 21 killed and dozens wounded as blasts triggered by. at least 18 killed as bomb attacks rock central baghdad ajenglish. at least 21 killed and dozens wounded as blasts triggered by suicide bomber and explosive ajenglish. 2 blasts in central baghdad kill at least 18 police say afp al jazeera. dozens also injured as two bombs explode at busy market in central al sinak neighbourhood. at least 21 killed and dozens wounded in baghdad after a suicide bombing\n\n['double bomb attack hits al sinak market killing at least 28 people. explosions triggered by suicide bomber and explosive ajenglish. at least 21 killed and dozens wounded in baghdad after a suicide bombing.']\n\ntwo blasts in central baghdad specifically in the al sinak market resulted in the deaths of at least 27 people and wounded 57 others the explosions occurred near car spare parts shops and were triggered by a suicide bomber and an explosive the attack took place in a crowded market causing dozens of injuries the death toll was later updated to at least 28 people the blasts were part of a series of bombings in central baghdad resulting in the deaths of at least 18 people\n","output_type":"stream"}]}]}
